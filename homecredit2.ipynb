{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5122890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports principais\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4930cace",
   "metadata": {},
   "source": [
    "### Funções Genéricas\n",
    "- Essas funções formam o “kit básico” de *ingestão* e *EDA* do projeto. Elas deixam o notebook mais limpo, evitam código repetido e permitem ajustes centralizados caso caminhos ou formatos mudem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb17aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_PARQUET = Path(\"data/parquet_files/train\")\n",
    "def read_parquet_dir(name: str) -> pl.DataFrame:\n",
    "    return pl.read_parquet(DATA_DIR_PARQUET / name)\n",
    "\n",
    "def ver_dataframe(dataframe: pd):\n",
    "    # Ver o número de linhas e colunas\n",
    "    print(\"Tamanho da tabela:\", dataframe.shape)\n",
    "\n",
    "    # Ver os nomes das primeiras 20 colunas e seus tipos\n",
    "    for nome, tipo in zip(dataframe.columns[:20], dataframe.dtypes[:20]):\n",
    "        print(f\"{nome:40} → {tipo}\")\n",
    "    \n",
    "    # Conta quantos valores vazios existem em cada coluna\n",
    "    faltantes = dataframe.null_count()\n",
    "    print(f\"\\nValores Nulos por Coluna\\n{faltantes}\")\n",
    "    \n",
    "    print(dataframe.head(5))\n",
    "\n",
    "def ver_coluna_df(dataframe: pd, coluna, lines=5):\n",
    "    # Conferir rapidamente\n",
    "    print(dataframe[\"date_decision\"].head(lines))\n",
    "    print(\"Tipo da coluna agora:\", dataframe[\"date_decision\"].dtype)\n",
    "    \n",
    "# Converter datas de texto/inteiro para Date\n",
    "def converter_texto_data(dataframe: pd, date_cols: list):\n",
    "    new_dataframe = dataframe\n",
    "    for col in date_cols:\n",
    "        new_dataframe = new_dataframe.with_columns(\n",
    "            pl.col(col)\n",
    "            .str.strptime(pl.Date, \"%Y-%m-%d\", strict=False)  # ajuste formato se precisar\n",
    "            .alias(col)\n",
    "        )\n",
    "    return new_dataframe\n",
    "    \n",
    "def ver_dist_column(dataframe: pd, columns):\n",
    "    dist_target = dataframe.select(pl.col(columns).value_counts())\n",
    "    print(dist_target)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ec8f37",
   "metadata": {},
   "source": [
    "## Importação do DataFrame Meste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58d476a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_master_dataframe(verbose: bool = True) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Carrega o arquivo principal (train_base.parquet),\n",
    "    converte a coluna date_decision para tipo Date\n",
    "    e faz uma inspeção básica opcional.\n",
    "\n",
    "    Parâmetros\n",
    "    ----------\n",
    "    verbose : bool (default=True)\n",
    "        Se True, imprime:\n",
    "        • shape, tipos e nulos            (ver_dataframe)\n",
    "        • amostra e dtype de date_decision (ver_coluna_df)\n",
    "        • distribuição do target           (ver_dist_column)\n",
    "\n",
    "    Retorno\n",
    "    -------\n",
    "    pl.DataFrame\n",
    "        DataFrame já limpo e pronto para receber features.\n",
    "    \"\"\"\n",
    "    # 1. Lê o arquivo Parquet base\n",
    "    df = read_parquet_dir(\"train_base.parquet\")\n",
    "\n",
    "    # 2. Converte a coluna de data\n",
    "    df = converter_texto_data(df, [\"date_decision\"])\n",
    "\n",
    "    # 3. EDA rápida (opcional)\n",
    "    if verbose:\n",
    "        ver_dataframe(df)\n",
    "        ver_coluna_df(df, \"date_decision\")\n",
    "        ver_dist_column(df, \"target\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7db69d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da tabela: (1526659, 5)\n",
      "case_id                                  → Int64\n",
      "date_decision                            → Date\n",
      "MONTH                                    → Int64\n",
      "WEEK_NUM                                 → Int64\n",
      "target                                   → Int64\n",
      "\n",
      "Valores Nulos por Coluna\n",
      "shape: (1, 5)\n",
      "┌─────────┬───────────────┬───────┬──────────┬────────┐\n",
      "│ case_id ┆ date_decision ┆ MONTH ┆ WEEK_NUM ┆ target │\n",
      "│ ---     ┆ ---           ┆ ---   ┆ ---      ┆ ---    │\n",
      "│ u32     ┆ u32           ┆ u32   ┆ u32      ┆ u32    │\n",
      "╞═════════╪═══════════════╪═══════╪══════════╪════════╡\n",
      "│ 0       ┆ 0             ┆ 0     ┆ 0        ┆ 0      │\n",
      "└─────────┴───────────────┴───────┴──────────┴────────┘\n",
      "shape: (5, 5)\n",
      "┌─────────┬───────────────┬────────┬──────────┬────────┐\n",
      "│ case_id ┆ date_decision ┆ MONTH  ┆ WEEK_NUM ┆ target │\n",
      "│ ---     ┆ ---           ┆ ---    ┆ ---      ┆ ---    │\n",
      "│ i64     ┆ date          ┆ i64    ┆ i64      ┆ i64    │\n",
      "╞═════════╪═══════════════╪════════╪══════════╪════════╡\n",
      "│ 0       ┆ 2019-01-03    ┆ 201901 ┆ 0        ┆ 0      │\n",
      "│ 1       ┆ 2019-01-03    ┆ 201901 ┆ 0        ┆ 0      │\n",
      "│ 2       ┆ 2019-01-04    ┆ 201901 ┆ 0        ┆ 0      │\n",
      "│ 3       ┆ 2019-01-03    ┆ 201901 ┆ 0        ┆ 0      │\n",
      "│ 4       ┆ 2019-01-04    ┆ 201901 ┆ 0        ┆ 1      │\n",
      "└─────────┴───────────────┴────────┴──────────┴────────┘\n",
      "shape: (5,)\n",
      "Series: 'date_decision' [date]\n",
      "[\n",
      "\t2019-01-03\n",
      "\t2019-01-03\n",
      "\t2019-01-04\n",
      "\t2019-01-03\n",
      "\t2019-01-04\n",
      "]\n",
      "Tipo da coluna agora: Date\n",
      "shape: (2, 1)\n",
      "┌─────────────┐\n",
      "│ target      │\n",
      "│ ---         │\n",
      "│ struct[2]   │\n",
      "╞═════════════╡\n",
      "│ {0,1478665} │\n",
      "│ {1,47994}   │\n",
      "└─────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = load_master_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35c014e",
   "metadata": {},
   "source": [
    "## Depósito features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b8c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_deposit_features(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    # 1. Carrega os dados de depósito\n",
    "    dep = read_parquet_dir(\"train_deposit_1.parquet\")\n",
    "    \n",
    "    # 2. Converte colunas de data\n",
    "    dep = converter_texto_data(dep, [\"openingdate_313D\", \"contractenddate_991D\"])\n",
    "    \n",
    "    # 3. Tratar nulos: flag + preenchimento provisório\n",
    "    dep = dep.with_columns([\n",
    "        pl.col(\"contractenddate_991D\").is_null().cast(pl.Int8).alias(\"dep_active_flag\"),\n",
    "        pl.when(pl.col(\"contractenddate_991D\").is_null())\n",
    "          .then(pl.col(\"openingdate_313D\"))\n",
    "          .otherwise(pl.col(\"contractenddate_991D\"))\n",
    "          .alias(\"contractenddate_991D\")\n",
    "    ])\n",
    "    \n",
    "    # 4. Cria coluna de duração do contrato\n",
    "    dep = dep.with_columns(\n",
    "        (pl.col(\"contractenddate_991D\") - pl.col(\"openingdate_313D\"))\n",
    "        .dt.total_days()\n",
    "        .alias(\"dep_contract_duration\")\n",
    "    )\n",
    "    \n",
    "    # 5. Agregação por cliente\n",
    "    dep_agg = dep.group_by(\"case_id\").agg([\n",
    "        pl.col(\"amount_416A\").mean().alias(\"dep_amt_mean\"),\n",
    "        pl.col(\"amount_416A\").max().alias(\"dep_amt_max\"),\n",
    "        pl.count().alias(\"dep_ops_cnt\"),\n",
    "        pl.col(\"dep_active_flag\").max().alias(\"dep_has_active\"),\n",
    "        pl.col(\"dep_contract_duration\").mean().alias(\"dep_dur_mean\")\n",
    "    ])\n",
    "    \n",
    "    # 6. Junta com a base principal\n",
    "    df = df.join(dep_agg, on=\"case_id\", how=\"left\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9206cf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da tabela: (1526659, 10)\n",
      "case_id                                  → Int64\n",
      "date_decision                            → Date\n",
      "MONTH                                    → Int64\n",
      "WEEK_NUM                                 → Int64\n",
      "target                                   → Int64\n",
      "dep_amt_mean                             → Float64\n",
      "dep_amt_max                              → Float64\n",
      "dep_ops_cnt                              → UInt32\n",
      "dep_has_active                           → Int8\n",
      "dep_dur_mean                             → Float64\n",
      "\n",
      "Valores Nulos por Coluna\n",
      "shape: (1, 10)\n",
      "┌─────────┬─────────────┬───────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
      "│ case_id ┆ date_decisi ┆ MONTH ┆ WEEK_NUM ┆ … ┆ dep_amt_ma ┆ dep_ops_cn ┆ dep_has_ac ┆ dep_dur_me │\n",
      "│ ---     ┆ on          ┆ ---   ┆ ---      ┆   ┆ x          ┆ t          ┆ tive       ┆ an         │\n",
      "│ u32     ┆ ---         ┆ u32   ┆ u32      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
      "│         ┆ u32         ┆       ┆          ┆   ┆ u32        ┆ u32        ┆ u32        ┆ u32        │\n",
      "╞═════════╪═════════════╪═══════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ 0       ┆ 0           ┆ 0     ┆ 0        ┆ … ┆ 1421548    ┆ 1421548    ┆ 1421548    ┆ 1421548    │\n",
      "└─────────┴─────────────┴───────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘\n",
      "shape: (5, 10)\n",
      "┌─────────┬────────────┬────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
      "│ case_id ┆ date_decis ┆ MONTH  ┆ WEEK_NUM ┆ … ┆ dep_amt_ma ┆ dep_ops_cn ┆ dep_has_ac ┆ dep_dur_me │\n",
      "│ ---     ┆ ion        ┆ ---    ┆ ---      ┆   ┆ x          ┆ t          ┆ tive       ┆ an         │\n",
      "│ i64     ┆ ---        ┆ i64    ┆ i64      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
      "│         ┆ date       ┆        ┆          ┆   ┆ f64        ┆ u32        ┆ i8         ┆ f64        │\n",
      "╞═════════╪════════════╪════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ 0       ┆ 2019-01-03 ┆ 201901 ┆ 0        ┆ … ┆ null       ┆ null       ┆ null       ┆ null       │\n",
      "│ 1       ┆ 2019-01-03 ┆ 201901 ┆ 0        ┆ … ┆ null       ┆ null       ┆ null       ┆ null       │\n",
      "│ 2       ┆ 2019-01-04 ┆ 201901 ┆ 0        ┆ … ┆ null       ┆ null       ┆ null       ┆ null       │\n",
      "│ 3       ┆ 2019-01-03 ┆ 201901 ┆ 0        ┆ … ┆ null       ┆ null       ┆ null       ┆ null       │\n",
      "│ 4       ┆ 2019-01-04 ┆ 201901 ┆ 0        ┆ … ┆ null       ┆ null       ┆ null       ┆ null       │\n",
      "└─────────┴────────────┴────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelve\\AppData\\Local\\Temp\\ipykernel_9740\\1673889712.py:28: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"dep_ops_cnt\"),\n"
     ]
    }
   ],
   "source": [
    "df = add_deposit_features(df)\n",
    "ver_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47432ce",
   "metadata": {},
   "source": [
    "## Person features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e2da448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_person1_features(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Extrai e agrega informações de train_person_1.parquet:\n",
    "      - idade média\n",
    "      - número médio de filhos\n",
    "      - % de registros femininos\n",
    "      - quantidade de registros\n",
    "    \"\"\"\n",
    "    person = read_parquet_dir(\"train_person_1.parquet\")\n",
    "\n",
    "    # 1. Converter coluna de nascimento para Date\n",
    "    person = converter_texto_data(person, [\"birth_259D\"])\n",
    "\n",
    "    # 2. Novas colunas auxiliares\n",
    "    person = person.with_columns([\n",
    "        (pl.lit(2025) - pl.col(\"birth_259D\").dt.year()).alias(\"idade\"),\n",
    "        (pl.col(\"gender_992L\") == \"F\").cast(pl.Int8).alias(\"is_female\")\n",
    "    ])\n",
    "\n",
    "    # 3. Agregação por case_id\n",
    "    person_agg = (\n",
    "        person.group_by(\"case_id\")\n",
    "              .agg([\n",
    "                  pl.col(\"idade\").mean().alias(\"person_age_mean\"),\n",
    "                  pl.col(\"childnum_185L\").mean().alias(\"person_child_avg\"),\n",
    "                  pl.col(\"is_female\").mean().alias(\"person_pct_female\"),\n",
    "                  pl.count().alias(\"person_record_count\")\n",
    "              ])\n",
    "    )\n",
    "\n",
    "    # 4. Join com a base principal\n",
    "    df = df.join(person_agg, on=\"case_id\", how=\"left\")\n",
    "\n",
    "    # 5. Preencher nulos apenas nas colunas criadas\n",
    "    fill_cols = [\n",
    "        \"person_age_mean\",\n",
    "        \"person_child_avg\",\n",
    "        \"person_pct_female\",\n",
    "        \"person_record_count\"\n",
    "    ]\n",
    "    df = df.with_columns([\n",
    "        pl.col(c).fill_null(0).alias(c) for c in fill_cols\n",
    "    ])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "860addb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelve\\AppData\\Local\\Temp\\ipykernel_9740\\3021984987.py:27: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"person_record_count\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da tabela: (1526659, 14)\n",
      "case_id                                  → Int64\n",
      "date_decision                            → Date\n",
      "MONTH                                    → Int64\n",
      "WEEK_NUM                                 → Int64\n",
      "target                                   → Int64\n",
      "dep_amt_mean                             → Float64\n",
      "dep_amt_max                              → Float64\n",
      "dep_ops_cnt                              → UInt32\n",
      "dep_has_active                           → Int8\n",
      "dep_dur_mean                             → Float64\n",
      "person_age_mean                          → Float64\n",
      "person_child_avg                         → Float64\n",
      "person_pct_female                        → Float64\n",
      "person_record_count                      → UInt32\n",
      "\n",
      "Valores Nulos por Coluna\n",
      "shape: (1, 14)\n",
      "┌─────────┬─────────────┬───────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
      "│ case_id ┆ date_decisi ┆ MONTH ┆ WEEK_NUM ┆ … ┆ person_age ┆ person_chi ┆ person_pct ┆ person_rec │\n",
      "│ ---     ┆ on          ┆ ---   ┆ ---      ┆   ┆ _mean      ┆ ld_avg     ┆ _female    ┆ ord_count  │\n",
      "│ u32     ┆ ---         ┆ u32   ┆ u32      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
      "│         ┆ u32         ┆       ┆          ┆   ┆ u32        ┆ u32        ┆ u32        ┆ u32        │\n",
      "╞═════════╪═════════════╪═══════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ 0       ┆ 0           ┆ 0     ┆ 0        ┆ … ┆ 0          ┆ 0          ┆ 0          ┆ 0          │\n",
      "└─────────┴─────────────┴───────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘\n",
      "shape: (5, 14)\n",
      "┌─────────┬────────────┬────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
      "│ case_id ┆ date_decis ┆ MONTH  ┆ WEEK_NUM ┆ … ┆ person_age ┆ person_chi ┆ person_pct ┆ person_rec │\n",
      "│ ---     ┆ ion        ┆ ---    ┆ ---      ┆   ┆ _mean      ┆ ld_avg     ┆ _female    ┆ ord_count  │\n",
      "│ i64     ┆ ---        ┆ i64    ┆ i64      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
      "│         ┆ date       ┆        ┆          ┆   ┆ f64        ┆ f64        ┆ f64        ┆ u32        │\n",
      "╞═════════╪════════════╪════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ 0       ┆ 2019-01-03 ┆ 201901 ┆ 0        ┆ … ┆ 39.0       ┆ 0.0        ┆ 0.0        ┆ 4          │\n",
      "│ 1       ┆ 2019-01-03 ┆ 201901 ┆ 0        ┆ … ┆ 68.0       ┆ 0.0        ┆ 0.0        ┆ 5          │\n",
      "│ 2       ┆ 2019-01-04 ┆ 201901 ┆ 0        ┆ … ┆ 51.0       ┆ 0.0        ┆ 0.0        ┆ 5          │\n",
      "│ 3       ┆ 2019-01-03 ┆ 201901 ┆ 0        ┆ … ┆ 32.0       ┆ 0.0        ┆ 0.0        ┆ 3          │\n",
      "│ 4       ┆ 2019-01-04 ┆ 201901 ┆ 0        ┆ … ┆ 31.0       ┆ 0.0        ┆ 0.0        ┆ 4          │\n",
      "└─────────┴────────────┴────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = add_person1_features(df)\n",
    "ver_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9e23bb",
   "metadata": {},
   "source": [
    "## Crédito features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e01acb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_credit_bureau_b1_features(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Agrega estatísticas do arquivo train_credit_bureau_b_1.parquet\n",
    "    (depth 1 – Bureau B).\n",
    "    Cria colunas numéricas e preenche nulos com 0.\n",
    "    \"\"\"\n",
    "    cb = read_parquet_dir(\"train_credit_bureau_b_1.parquet\")\n",
    "\n",
    "    # 1) Converter datas de contrato\n",
    "    cb = converter_texto_data(cb, [\"contractdate_551D\"])\n",
    "\n",
    "    # 2) Dias desde o contrato mais recente\n",
    "    latest_date = cb[\"contractdate_551D\"].max()\n",
    "    cb = cb.with_columns(\n",
    "        (latest_date - pl.col(\"contractdate_551D\"))\n",
    "        .dt.total_days()\n",
    "        .alias(\"recency_days\")\n",
    "    )\n",
    "\n",
    "    # 3) Agregação segura (só usa colunas se realmente existirem)\n",
    "    agg_exprs = [\n",
    "        pl.col(\"amount_1115A\").sum().alias(\"cb_b1_amt_sum\"),\n",
    "        pl.col(\"amount_1115A\").max().alias(\"cb_b1_amt_max\"),\n",
    "        pl.col(\"recency_days\").min().alias(\"cb_b1_recency_days\"),\n",
    "        pl.count().alias(\"cb_b1_cnt\")\n",
    "    ]\n",
    "\n",
    "    if \"dpd_550P\" in cb.columns:\n",
    "        agg_exprs.append(pl.col(\"dpd_550P\").mean().alias(\"dpd_550_mean\"))\n",
    "    if \"dpd_733P\" in cb.columns:\n",
    "        agg_exprs.append(pl.col(\"dpd_733P\").mean().alias(\"dpd_733_mean\"))\n",
    "    if \"dpdmax_851P\" in cb.columns:\n",
    "        agg_exprs.append(pl.col(\"dpdmax_851P\").mean().alias(\"dpdmax_851_mean\"))\n",
    "\n",
    "    if {\"debtpastduevalue_732A\", \"debtvalue_227A\"}.issubset(cb.columns):\n",
    "        agg_exprs.append(\n",
    "            (pl.col(\"debtpastduevalue_732A\").sum() /\n",
    "             pl.when(pl.col(\"debtvalue_227A\").sum() == 0)\n",
    "               .then(1)\n",
    "               .otherwise(pl.col(\"debtvalue_227A\").sum())\n",
    "            ).alias(\"cb_b1_debt_due_ratio\")\n",
    "        )\n",
    "\n",
    "    cb_agg = cb.group_by(\"case_id\").agg(agg_exprs)\n",
    "\n",
    "    # 4) Combinar médias em DPD geral e máximo\n",
    "    dpd_cols = [c for c in [\"dpd_550_mean\", \"dpd_733_mean\", \"dpdmax_851_mean\"] if c in cb_agg.columns]\n",
    "\n",
    "    if dpd_cols:\n",
    "        cb_agg = cb_agg.with_columns([\n",
    "            pl.concat_list([pl.col(c) for c in dpd_cols]).list.mean().alias(\"cb_b1_dpd_mean\"),\n",
    "            pl.concat_list([pl.col(c) for c in dpd_cols]).list.max().alias(\"cb_b1_dpd_max\")\n",
    "        ])\n",
    "\n",
    "    # 5) Juntar na base principal\n",
    "    df = df.join(cb_agg, on=\"case_id\", how=\"left\")\n",
    "\n",
    "    # 6) Preencher nulos das novas colunas com 0\n",
    "    new_cols = [c for c in cb_agg.columns if c != \"case_id\"]\n",
    "    df = df.with_columns([pl.col(c).fill_null(0).alias(c) for c in new_cols])\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b23a17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho da tabela: (1526659, 24)\n",
      "case_id                                  → Int64\n",
      "date_decision                            → Date\n",
      "MONTH                                    → Int64\n",
      "WEEK_NUM                                 → Int64\n",
      "target                                   → Int64\n",
      "dep_amt_mean                             → Float64\n",
      "dep_amt_max                              → Float64\n",
      "dep_ops_cnt                              → UInt32\n",
      "dep_has_active                           → Int8\n",
      "dep_dur_mean                             → Float64\n",
      "person_age_mean                          → Float64\n",
      "person_child_avg                         → Float64\n",
      "person_pct_female                        → Float64\n",
      "person_record_count                      → UInt32\n",
      "cb_b1_amt_sum                            → Float64\n",
      "cb_b1_amt_max                            → Float64\n",
      "cb_b1_recency_days                       → Int64\n",
      "cb_b1_cnt                                → UInt32\n",
      "dpd_550_mean                             → Float64\n",
      "dpd_733_mean                             → Float64\n",
      "\n",
      "Valores Nulos por Coluna\n",
      "shape: (1, 24)\n",
      "┌─────────┬─────────────┬───────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
      "│ case_id ┆ date_decisi ┆ MONTH ┆ WEEK_NUM ┆ … ┆ dpdmax_851 ┆ cb_b1_debt ┆ cb_b1_dpd_ ┆ cb_b1_dpd_ │\n",
      "│ ---     ┆ on          ┆ ---   ┆ ---      ┆   ┆ _mean      ┆ _due_ratio ┆ mean       ┆ max        │\n",
      "│ u32     ┆ ---         ┆ u32   ┆ u32      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
      "│         ┆ u32         ┆       ┆          ┆   ┆ u32        ┆ u32        ┆ u32        ┆ u32        │\n",
      "╞═════════╪═════════════╪═══════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ 0       ┆ 0           ┆ 0     ┆ 0        ┆ … ┆ 0          ┆ 0          ┆ 0          ┆ 0          │\n",
      "└─────────┴─────────────┴───────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘\n",
      "shape: (5, 24)\n",
      "┌─────────┬────────────┬────────┬──────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
      "│ case_id ┆ date_decis ┆ MONTH  ┆ WEEK_NUM ┆ … ┆ dpdmax_851 ┆ cb_b1_debt ┆ cb_b1_dpd_ ┆ cb_b1_dpd_ │\n",
      "│ ---     ┆ ion        ┆ ---    ┆ ---      ┆   ┆ _mean      ┆ _due_ratio ┆ mean       ┆ max        │\n",
      "│ i64     ┆ ---        ┆ i64    ┆ i64      ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
      "│         ┆ date       ┆        ┆          ┆   ┆ f64        ┆ f64        ┆ f64        ┆ f64        │\n",
      "╞═════════╪════════════╪════════╪══════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
      "│ 0       ┆ 2019-01-03 ┆ 201901 ┆ 0        ┆ … ┆ 0.0        ┆ 0.0        ┆ 0.0        ┆ 0.0        │\n",
      "│ 1       ┆ 2019-01-03 ┆ 201901 ┆ 0        ┆ … ┆ 0.0        ┆ 0.0        ┆ 0.0        ┆ 0.0        │\n",
      "│ 2       ┆ 2019-01-04 ┆ 201901 ┆ 0        ┆ … ┆ 0.0        ┆ 0.0        ┆ 0.0        ┆ 0.0        │\n",
      "│ 3       ┆ 2019-01-03 ┆ 201901 ┆ 0        ┆ … ┆ 0.0        ┆ 0.0        ┆ 0.0        ┆ 0.0        │\n",
      "│ 4       ┆ 2019-01-04 ┆ 201901 ┆ 0        ┆ … ┆ 0.0        ┆ 0.0        ┆ 0.0        ┆ 0.0        │\n",
      "└─────────┴────────────┴────────┴──────────┴───┴────────────┴────────────┴────────────┴────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kelve\\AppData\\Local\\Temp\\ipykernel_9740\\1190808682.py:25: DeprecationWarning: `pl.count()` is deprecated. Please use `pl.len()` instead.\n",
      "(Deprecated in version 0.20.5)\n",
      "  pl.count().alias(\"cb_b1_cnt\")\n"
     ]
    }
   ],
   "source": [
    "df = add_credit_bureau_b1_features(df)\n",
    "ver_dataframe(df)          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d419c",
   "metadata": {},
   "source": [
    "## Funções para Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd4e35df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numeric_columns(df: pl.DataFrame, drop: list[str] = [\"target\"]) -> list[str]:\n",
    "    return [\n",
    "        col for col, dtype in zip(df.columns, df.dtypes)\n",
    "        if dtype in (pl.Int8, pl.Int16, pl.Int32, pl.Int64, pl.UInt8, pl.UInt16,\n",
    "                     pl.UInt32, pl.UInt64, pl.Float32, pl.Float64)\n",
    "        and col not in drop\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1ba20e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_valid(df: pl.DataFrame, num_cols: list[str], stratify: bool = True):\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X = df.select(num_cols).to_pandas()\n",
    "    y = df[\"target\"].to_pandas()\n",
    "\n",
    "    if stratify:\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "    else:\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "046a8cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lightgbm(X_train, y_train, X_valid, y_valid) -> tuple[lgb.Booster, float, float]:\n",
    "    import lightgbm as lgb\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    train_set = lgb.Dataset(X_train, y_train)\n",
    "    valid_set = lgb.Dataset(X_valid, y_valid, reference=train_set)\n",
    "\n",
    "    params = dict(\n",
    "        objective=\"binary\",\n",
    "        learning_rate=0.05,\n",
    "        num_leaves=64,\n",
    "        feature_fraction=0.8,\n",
    "        bagging_fraction=0.8,\n",
    "        bagging_freq=1,\n",
    "        metric=\"auc\",\n",
    "        verbose=-1,\n",
    "        is_unbalance=True\n",
    "    )\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set,\n",
    "        valid_sets=[valid_set],\n",
    "        num_boost_round=500,\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    "    )\n",
    "\n",
    "    pred_valid = model.predict(X_valid, num_iteration=model.best_iteration)\n",
    "    auc = roc_auc_score(y_valid, pred_valid)\n",
    "    gini = 2 * auc - 1\n",
    "\n",
    "    print(f\"\\nAUC  : {auc:.4f}\")\n",
    "    print(f\"Gini : {gini:.4f}\")\n",
    "\n",
    "    return model, auc, gini\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9aef82",
   "metadata": {},
   "source": [
    "## Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "820fb771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's auc: 0.635081\n",
      "\n",
      "AUC  : 0.6351\n",
      "Gini : 0.2702\n"
     ]
    }
   ],
   "source": [
    "num_cols = get_numeric_columns(df)\n",
    "X_train, X_valid, y_train, y_valid = prepare_train_valid(df, num_cols)\n",
    "model, auc, gini = train_lightgbm(X_train, y_train, X_valid, y_valid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
